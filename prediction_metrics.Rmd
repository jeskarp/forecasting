---
title: "Prediction Metrics"
author: "Janetta E. Skarp"
date: "13 April 2018"
output: pdf_document
fonsize: 11pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

# The data

Assume that I have daily case data for an outbreak. The outbreak of choice is an H1N1 influenza outbreak in Pennsylvania in 2009 (EpiEstim). There is data for 32 days, but I will pretend that I only have data for the first 2 weeks. I assume that the data is complete and devoid of reporting delays. I am aware that this is an unrealistic expectation for real data but this assumption works for my example.

```{r data}
library(EpiEstim) # need the EpiEstim package for data
data("Flu2009") # Load the flu data
Flu2009 # Look at what the full dataset contains
```

Let's have a look at the incidence curve for the outbreak.

```{r incidence_curve}
library(ggplot2)

# Truncate the dataset and make incidence into its own dataframe
length_obs <- 14 # length of observation period in days
end <- length(Flu2009$Incidence)

# Convert to a dataframe for ggplot
Flu2009_incidence <- data.frame(Flu2009$Incidence[1:length_obs]) 
names(Flu2009_incidence) <- c("Incidence") # Rename the variable

# Add a "day" column to the dataset to help plotting
day_sequence <- seq(1, length_obs, 1)
Flu2009_incidence$Day <- day_sequence

incidence_curve <- ggplot(data = Flu2009_incidence, aes(x = Flu2009_incidence$Day, 
                                                        y = Flu2009_incidence$Incidence)) +
                   geom_bar(stat="identity")
incidence_curve

```

\newpage
# Estimating R

Next, I'll generate a forecast so that I can assess its performance later. 

The EpiEstim package provides an estimate of the serial interval Gamma distribution already so I don't need to calculate it:

```{r serial_interval, echo = FALSE}
# Make the serial interval distribution into a dataframe
Flu2009_si <- data.frame(Flu2009$SI.Distr)
SI_end <- length(Flu2009$SI.Distr)

# Plot the serial interval
serial_interval <- ggplot(data = Flu2009_si, aes(x = seq(1:SI_end), 
                                                 y = Flu2009_si$Flu2009.SI.Distr)) +
                   geom_bar(stat="identity")
serial_interval

```

The mean of the distribution is 2.6 days.

The standard deviation of the distribution is 1.5 days.

The shift of the distribution is 1 day.

I can now estimate R:
```{r R_estimate}
library(earlyR)

# Specifying the input for the estimate
mu <- 2.6 # serial interval mean
sigma <- 1.5 # serial interval SD
i <- c(Flu2009$Incidence[1:length_obs]) # incidence vector
typeof(i)

# The R estimation
R <- get_R(as.integer(i), disease = NULL, si = NULL, si_mean = mu, si_sd = sigma, 
           max_R = 10)
print(R)

# Visualising R
plot(R)
plot(R, "lambdas")
abline(v = max(Flu2009_incidence$Day), lty = 2)

```

The dotted lines in the global force of infection plot show the current date (i.e. last date observed). There is still a possibility of a new transmission event occurring. 

\newpage
# Incidence forecasting

Now that I know what's happening with the effective reproduction number, I can forecast into the future to predict what will happen next.

The *projections* package will not work unless you feed incidence to it as an incidence object (using the package *incidence*), so I'll need to re-make my daily incidence:
```{r redo_incidence}
library(incidence)

Flu2009_incidence # what I'll be converting to an incidence object

# Need to open up the incidence so that there's only 1 individual per row with
# their date of becoming a case (assume date of onset is the case date)
Flu2009_infday <- array(NA, dim = c(sum(Flu2009_incidence$Incidence)))

for (i in 1:nrow(Flu2009_incidence)) {
  if (Flu2009_incidence$Incidence[i] > 0) {
    # create an array for the number of individuals who have the same date of infection
    number_cases <- array(Flu2009_incidence$Day[i], 
                          dim = c(Flu2009_incidence$Incidence[i])) 
    # calculate where in the new array the cases for day i should be added to
    addition_point <- sum(Flu2009_incidence$Incidence[0:(i-1)]) + 1 
    # add the cases for day i to the big array
    Flu2009_infday[(addition_point):(addition_point+length(number_cases)-1)] <- Flu2009_incidence$Day[i] 
  }
}

Flu2009_infday # The current shape of incidence

# Now convert this "line list" into an incidence object
Flu2009_newinc <- incidence(dates = as.numeric(Flu2009_infday), interval = 1)
plot(Flu2009_newinc)
```

```{r forecast}
library(projections)

# number of days that I hid data for
hidden_days <- end - length_obs

# Number of trajectories for the projection
n_traj <- 10000 

# Serial interval distribution already provided with the EpiEstim data
proj <- project(Flu2009_newinc, R = sample_R(R, 1000), si = Flu2009$SI.Distr, 
                n_sim = n_traj, n_days = hidden_days, R_fix_within = TRUE)

# Make a data frame of the hidden data for comparison when plotting
Flu2009_incidence_hidden <- data.frame(Flu2009$Incidence[length_obs + 1:end])
Flu2009_incidence_hidden <- data.frame(Flu2009_incidence_hidden[1:hidden_days, ])
names(Flu2009_incidence_hidden) <- c("Incidence") # Rename the variable
Flu2009_incidence_hidden$Day <- seq((length_obs + 1), end, 1)

# Look at prediction quantiles
apply(proj, 1, summary)

# Look at how the mean develops
apply(proj, 1, function(x) mean(x > 0))

# Plot the projection
plot(proj, c(.1, .9)) +
  # Add a line showing the actual incidence for days 15-32
  geom_line(aes(x = Day, y = Incidence), Flu2009_incidence_hidden)

```

According to the predictions, it looks like the outbreak incidence will be increasing over the next 18 days. The uncertainty around the prediction estimates increases as the forecast moves further into the future. Compared to the true incidence (black line), the forecast stays near the prediction for around 3 days, after which the prediction starts to grossly overestimate incidence.

# Assessing prediction performance

As done by Funk et al. 

## Calibration
Calibration relates to the model's ability to correctly identify prediction uncertainty. Calibration needs to be assessed before sharpness.

If the model is perfectly calibrated, each time point's data looks as if it comes from the predictive probability distribution (the distribution of possible unobserved values conditional on the observed values) for that time point:

$$ u_{t} = F_{t}(x_{t}) $$
Here $x_{t}$ is the datapoint for time $t$. $F_{t}$ is the cumulative probability distribution at time $t$. $u_{t}$ is the probability.

In my case the predictions should follow a Poisson-distribution with some lambda, $\lambda$. I then use my hidden data as the true data points, $x_{t}$.

The Anderson-Darling test (a statistical test for seeing if the data is drawn from a given probability distribution) of uniformity to $u_{t}$ is applied. The model is calibrated if p > 0.1.

```{r calibration}
library("goftest")

# The true datapoints: x_t
x_t <- Flu2009_incidence_hidden$Incidence

# The cumulative probability distribution for time t: F_t
cumulative_poisson <- function(data, pred){
  ppois(data, mean(pred))
}

# Calculating calibration for each prediction day
calibration <- function(data, pred){
  calibration <- array(NA, dim = c(hidden_days))
  for (i in 1:hidden_days){
    calibration[i] <- cumulative_poisson(data[i], pred[i, ])
  }
  return(calibration)
}

# anderson-darling <- function(data, pred){
#   anderson-darling <- array(NA, dim = c(hidden_days))
#   for (i in 1:hidden_days){
#   ad.test()
#   }
#   return(anderson-darling)
# }

model_calibration <- calibration(x_t, proj)

```

```{r plot_calibration, echo = FALSE}
calibration_days <- seq(1, hidden_days, 1)
calibration_data <- data.frame(model_calibration)
calibration_data$days <- calibration_days

plot_calibration <- ggplot(data = calibration_data, aes(x = days, 
                                                        y = model_calibration)) +
                           geom_point(size = 2, shape = 16) 
plot_calibration

```

The model is kind of calibrated for the first 3 days (also intuitively seen in the previous plot), but after that calibration drops.

## Sharpness
Model's ability to make predictions within a narrow range of possible outcomes. 

Sharpness is calculated as follows:

$$ S_{t}(F_{t}) = 1 - \frac{MADM(y)}{m(y)} $$
where y is the prediction variable. MADM stands for the normalised median absolute deviation around the median (m(y)) of y:

$$ MADM(y) = m(|y - m(y)|) $$
The closer to 1 S is, the sharper the forecast.

```{r sharpness, cache = TRUE}
# Function for calculating forecasted incidence median
forecast_median <- function(x){
  return(median(x))
}

# Function for calculating the standard deviations
# Want it to return MADM(y)
MADM <- function(x){
  traj_diff <- array(NA, dim = c(n_traj)) # array for storing SDs
  # For each trajectory for this day, calculate the SD
  for (i in 1:n_traj){
    absolute_diff <-  abs(x[i] - forecast_median(x))
    # save the absolute difference for each trajectory
    traj_diff[i] <- absolute_diff
  }
  MADM <- median(traj_diff)
  return(MADM)
}

# Function for calculating the normalised median absolute deviation
# Want it to return St(Ft)
sharpness <- function(x){
  # array for storing daily sharpness
  sharpness <- array(NA, dim = c(hidden_days))
  for (i in 1:hidden_days){
    sharpness_day <- 1 - (MADM(x[i, ]) / forecast_median(x[i, ])) 
    sharpness[i] <- sharpness_day
  }
  return(sharpness)
}

model_sharpness <- sharpness(proj)

```

```{r plot_sharpness, echo = FALSE}
sharpness_days <- seq(1, hidden_days, 1)
sharpness_data <- data.frame(model_sharpness)
sharpness_data$days <- sharpness_days

plot_sharpness <- ggplot(data = sharpness_data, aes(x = days, 
                                                    y = model_sharpness)) +
                           geom_point(size = 2, shape = 16) 
plot_sharpness

```

Model sharpness decreases as you forecast further. Remember, S = 1 is perfect sharpness.

## Bias
Does model systematically over- or underpredict data?

If unbiased, half of forecasts would be above estimate and half would be below the estimate, thus $B_{t}$ would be 0. A completely biased model would either be completely above the prediction line ($B_{t} = 1$) or completely under the prediction line ($B_{t} = -1$).

The Heaviside function which takes a value of 0 for a negative number and 1 for a positive number.

## Continuous ranked probability score
Combines calibration and sharpness
